â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘             TRAINING FILES SUMMARY - What Each File Does                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              EXECUTION ENTRY POINTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ run_main.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Full end-to-end pipeline                                         â”‚
â”‚  Entry: main()                                                              â”‚
â”‚  Config: PipelineConfig class                                               â”‚
â”‚  Uses: train_sequence.py + test_sequence.py                                â”‚
â”‚  Output: runs/arc_full_run_YYYYMMDD_HHMMSS/                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ run_gpu_finetuned.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: GPU-accelerated training wrapper                                  â”‚
â”‚  Entry: main() â†’ calls trainloop_gpu_finetuned.main()                      â”‚
â”‚  Config: Command line args                                                  â”‚
â”‚  Uses: trainloop_gpu_finetuned.py                                          â”‚
â”‚  Output: runs/arc_gpu_finetuned_YYYYMMDD_HHMMSS/                          â”‚
â”‚  Special: Supports --freeze_qwen True/False (NEW!)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ run_cpu_simple.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: CPU-only lightweight training                                     â”‚
â”‚  Entry: main() â†’ calls trainloop.train_one_epoch()                         â”‚
â”‚  Config: Command line args                                                  â”‚
â”‚  Uses: trainloop.py                                                         â”‚
â”‚  Output: runs/arc_cpu_YYYYMMDD_HHMMSS/                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              CORE TRAINING FILES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ train_sequence.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: High-level training pipeline                                      â”‚
â”‚  Key Responsibilities:                                                      â”‚
â”‚    âœ“ Define TrainingConfig (epochs, batch_size, LR, etc.)                 â”‚
â”‚    âœ“ Create TrainingLogger (logs to JSONL files)                          â”‚
â”‚    âœ“ Main training loop (orchestrates per-epoch training)                  â”‚
â”‚    âœ“ Logging metrics to train_log.jsonl, eval_log.jsonl                  â”‚
â”‚                                                                             â”‚
â”‚  Key Classes:                                                               â”‚
â”‚    - TrainingConfig       (Training settings)                              â”‚
â”‚    - TrainingLogger       (Logging to files)                               â”‚
â”‚    - TrainingMetricsTracker (Metrics aggregation)                          â”‚
â”‚                                                                             â”‚
â”‚  Hardcoded Config (Lines 23-29):                                          â”‚
â”‚    TTA_EVAL_INTERVAL = 50                                                â”‚
â”‚    CHECKPOINT_INTERVAL = 100                                             â”‚
â”‚    GRAD_CLIP_NORM = 1.0                                                 â”‚
â”‚    LEARNING_RATE = 1e-3                                                 â”‚
â”‚    EPOCHS = 5                                                            â”‚
â”‚    BATCH_SIZE = 1                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ trainloop.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Single epoch training logic                                       â”‚
â”‚  Key Responsibilities:                                                      â”‚
â”‚    âœ“ Per-epoch loop (batches)                                             â”‚
â”‚    âœ“ Load batch, extract features                                         â”‚
â”‚    âœ“ Generate Qwen prompt                                                  â”‚
â”‚    âœ“ Train episode with agent                                             â”‚
â”‚    âœ“ RevThink revision (if needed)                                        â”‚
â”‚    âœ“ Backward pass + optimization                                         â”‚
â”‚                                                                             â”‚
â”‚  Key Functions:                                                             â”‚
â”‚    - train_one_epoch()    (Main epoch loop)                              â”‚
â”‚    - make_agent()         (Create ARCPromptGuidedAgent)                 â”‚
â”‚    - make_qwen()          (Create QwenHybridPrompt)                     â”‚
â”‚    - seed_all()           (Set random seeds)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ trainloop_gpu_finetuned.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: MAIN TRAINING SCRIPT (GPU-optimized)                              â”‚
â”‚  Key Responsibilities:                                                      â”‚
â”‚    âœ“ Initialize all models (agent, Qwen, EFE loss, solvers)              â”‚
â”‚    âœ“ Set up optimizers with per-component LR schedules                   â”‚
â”‚    âœ“ Main training loop (epochs)                                         â”‚
â”‚    âœ“ Checkpoint saving/loading                                           â”‚
â”‚    âœ“ Validation/evaluation                                               â”‚
â”‚    âœ“ Comprehensive logging                                               â”‚
â”‚                                                                             â”‚
â”‚  Function Parameters (Lines 505-509) - MAIN CONFIG!:                     â”‚
â”‚    epochs=10                  Total epochs to train                      â”‚
â”‚    agent_lr=1e-5              Agent learning rate                        â”‚
â”‚    qwen_lr=None               Qwen learning rate (if not frozen)         â”‚
â”‚    weight_decay=1e-6          L2 regularization                          â”‚
â”‚    grad_accum_steps=1         Gradient accumulation                      â”‚
â”‚    grad_clip=1.0              Gradient clipping norm                     â”‚
â”‚    warmup_steps=100           Warmup period                              â”‚
â”‚    max_batches_per_epoch=None Limit batches (None = full)                â”‚
â”‚    val_frequency=1            Eval every N epochs                        â”‚
â”‚    skip_test=False            Skip final test                            â”‚
â”‚    device="cuda"              Device (cuda/cpu)                          â”‚
â”‚    model_name=None            Qwen model ID override                     â”‚
â”‚    seed=42                    Random seed                                â”‚
â”‚    save_frequency=1           Save checkpoint freq                       â”‚
â”‚    freeze_qwen=True           ğŸ†• NEW: Control Qwen training!            â”‚
â”‚                                                                             â”‚
â”‚  Key Classes:                                                               â”‚
â”‚    - TrainingLogger          (Comprehensive logging)                      â”‚
â”‚    - TrainingMetricsTracker  (Metrics aggregation)                       â”‚
â”‚                                                                             â”‚
â”‚  Creates Models:                                                            â”‚
â”‚    1. ARCPromptGuidedAgent   (EFE loss agent)                           â”‚
â”‚    2. QwenHybridPrompt       (LLM prompt generation)                    â”‚
â”‚    3. PermanentSolver        (Solver2, long-term memory)                â”‚
â”‚    4. EFELoss               (Loss function)                             â”‚
â”‚    5. RevThinkOrchestrator   (Prompt revision)                          â”‚
â”‚    6. TestTimeAdaptationSystem (TTA)                                    â”‚
â”‚                                                                             â”‚
â”‚  Output Files:                                                              â”‚
â”‚    âœ“ train_log.jsonl         (Per-batch training metrics)               â”‚
â”‚    âœ“ eval_log.jsonl          (Per-epoch evaluation)                     â”‚
â”‚    âœ“ tta_log.jsonl           (TTA evaluation)                           â”‚
â”‚    âœ“ metrics.jsonl           (Summary metrics)                          â”‚
â”‚    âœ“ checkpoints.jsonl       (Checkpoint metadata)                      â”‚
â”‚    âœ“ checkpoints/*.pt        (Model checkpoints)                        â”‚
â”‚    âœ“ metrics_plot.png        (Loss curves)                              â”‚
â”‚    âœ“ training_log.txt        (Human-readable log)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ test_sequence.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Testing and evaluation pipeline                                   â”‚
â”‚  Key Responsibilities:                                                      â”‚
â”‚    âœ“ Evaluate on train/test splits                                       â”‚
â”‚    âœ“ Compute binary accuracy (strict ARC evaluation)                     â”‚
â”‚    âœ“ Optional TTA evaluation                                             â”‚
â”‚    âœ“ Batch checkpoint evaluation                                         â”‚
â”‚                                                                             â”‚
â”‚  Key Classes:                                                               â”‚
â”‚    - TestConfig             (Testing settings)                            â”‚
â”‚                                                                             â”‚
â”‚  Key Functions:                                                             â”‚
â”‚    - test_sequence()        (Main test loop)                            â”‚
â”‚    - batch_test_checkpoints() (Test multiple checkpoints)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                           MODEL ARCHITECTURE FILES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ loss_function.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: EFE Loss computation + Agent architecture                         â”‚
â”‚  Key Components:                                                            â”‚
â”‚    âœ“ EFELossConfig class (11 loss weights + profiles)                    â”‚
â”‚    âœ“ EFELoss class (forward computation)                                 â”‚
â”‚    âœ“ ARCPromptGuidedAgent class (forward/backward planning)              â”‚
â”‚                                                                             â”‚
â”‚  Config (Lines 25-88):                                                    â”‚
â”‚    EFELossConfig dataclass with 11 lambda parameters                    â”‚
â”‚    Pre-configured profiles:                                              â”‚
â”‚      - aggressive_grid_matching() [4Ã— grid matching boost]             â”‚
â”‚      - reversibility_focus() [0.8 reversibility weight]                 â”‚
â”‚      - balanced() [default]                                             â”‚
â”‚                                                                             â”‚
â”‚  Key Methods:                                                               â”‚
â”‚    - forward() [main loss computation]                                   â”‚
â”‚    - _compute_grid_matching_loss() [PRIMARY objective]                  â”‚
â”‚    - _compute_reversibility_loss() [invertibility check]                â”‚
â”‚    - train_episode() [complete training step]                           â”‚
â”‚    - forward_planning() [Qâ†’ predictions]                                â”‚
â”‚    - backward_planning() [Qâ† predictions]                               â”‚
â”‚                                                                             â”‚
â”‚  Loss Terms (9 total):                                                     â”‚
â”‚    1. Grid Matching (PRIMARY - unweighted)                               â”‚
â”‚    2. Risk (Î»=1.0)                                                      â”‚
â”‚    3. Ambiguity (Î»=0.0)                                                 â”‚
â”‚    4. Step Penalty (Î»=0.1)                                              â”‚
â”‚    5. Consistency (Î»=1.0)                                               â”‚
â”‚    6. Bidirectional (Î»=0.5)                                             â”‚
â”‚    7. Z-Anchoring (Î»=0.2)                                               â”‚
â”‚    8. Prompt Consistency (Î»=0.3)                                        â”‚
â”‚    9. Reversibility (Î»=0.4) [NEW]                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ qwen_hybrid_prompt.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Qwen LLM integration for prompt generation                        â”‚
â”‚  Key Components:                                                            â”‚
â”‚    âœ“ QwenCfg configuration class                                          â”‚
â”‚    âœ“ QwenHybridPrompt model                                              â”‚
â”‚    âœ“ Transformer-based feature encoding                                  â”‚
â”‚                                                                             â”‚
â”‚  Config (Lines 224-240):                                                  â”‚
â”‚    model_name = "Qwen/Qwen2.5-1.8B"                                     â”‚
â”‚    dtype = "float16"                                                    â”‚
â”‚    max_new_tokens = 96                                                  â”‚
â”‚    temperature = 0.0 (deterministic)                                    â”‚
â”‚    top_p = 0.9                                                          â”‚
â”‚    cache_dir = ".cache/hf"                                              â”‚
â”‚                                                                             â”‚
â”‚  Key Feature (NEW!):                                                        â”‚
â”‚    âœ“ Qwen is now UNFROZEN and trainable!                               â”‚
â”‚      (See line 279-283: Explicitly set requires_grad=True)             â”‚
â”‚                                                                             â”‚
â”‚  Key Methods:                                                               â”‚
â”‚    - forward() [generate prompt + embeddings]                           â”‚
â”‚    - __init__() [load and configure Qwen]                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ revthink_orchestrator.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Loss-based prompt revision orchestration                          â”‚
â”‚  Key Components:                                                            â”‚
â”‚    âœ“ RevThinkCfg configuration class                                      â”‚
â”‚    âœ“ RevThinkOrchestrator class                                          â”‚
â”‚                                                                             â”‚
â”‚  Config (Lines 7-13):                                                     â”‚
â”‚    tau = 0.45       Revision trigger threshold                         â”‚
â”‚    alpha = 2.0      Gate sharpness                                     â”‚
â”‚    beta = 0.3       Gate bias                                          â”‚
â”‚    gamma = 0.5      Lambda prompt boost factor                         â”‚
â”‚    eta = 0.2        Z-anchoring blend                                  â”‚
â”‚    mask_weight = 0.5                                                  â”‚
â”‚                                                                             â”‚
â”‚  Key Feature (NEW!):                                                        â”‚
â”‚    âœ“ Reversibility loss now weighted at 25% in revthink_score!       â”‚
â”‚    âœ“ Highest weight signal after consistency (20%)                    â”‚
â”‚    âœ“ Triggers prompt updates when backward planning fails             â”‚
â”‚                                                                             â”‚
â”‚  Key Methods:                                                               â”‚
â”‚    - maybe_revise() [decide to revise prompt]                         â”‚
â”‚    - revthink_score() [compute need for revision]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ tta.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Test-time adaptation during training                              â”‚
â”‚  Key Components:                                                            â”‚
â”‚    âœ“ TestTimeAdaptationSystem class                                       â”‚
â”‚    âœ“ SurpriseBasedMemory (memory management)                             â”‚
â”‚    âœ“ MetaAdapter (parameter adaptation)                                  â”‚
â”‚    âœ“ SolverRouter (solver selection)                                     â”‚
â”‚    âœ“ AdaptiveLikelihoodHead (likelihood adaptation)                      â”‚
â”‚                                                                             â”‚
â”‚  Config (Lines 33-48):                                                    â”‚
â”‚    memory_size = 1000                                                  â”‚
â”‚    surprise_threshold = 0.65                                           â”‚
â”‚    adaptation_steps = 5                                                â”‚
â”‚    adaptation_lr = 1e-3                                                â”‚
â”‚                                                                             â”‚
â”‚  Key Feature (NEW!):                                                        â”‚
â”‚    âœ“ train_time_adapt() method for TTA during training               â”‚
â”‚    âœ“ Surprise-gated memory writes                                    â”‚
â”‚    âœ“ Tracks TTA improvement per step                                â”‚
â”‚                                                                             â”‚
â”‚  Key Methods:                                                               â”‚
â”‚    - train_time_adapt() [TTA during training] [NEW]                   â”‚
â”‚    - test_time_adapt() [TTA at test time]                            â”‚
â”‚    - compute_surprise() [surprise-based gating]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ solver1.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Short-term contextual memory with pattern storage                 â”‚
â”‚  Key Components:                                                            â”‚
â”‚    âœ“ ContextualMemoryBank (fast episodic memory)                          â”‚
â”‚    âœ“ ContextualSolver (uses contextual memory)                            â”‚
â”‚    âœ“ Pattern storage system [NEW]                                         â”‚
â”‚                                                                             â”‚
â”‚  Config (Lines 28-40):                                                    â”‚
â”‚    context_size = 50                                                  â”‚
â”‚    surprise_threshold = 0.2                                           â”‚
â”‚    temporal_decay = 0.9                                               â”‚
â”‚                                                                             â”‚
â”‚  Key Features (NEW!):                                                       â”‚
â”‚    âœ“ store_known_pattern() [store successful patterns]               â”‚
â”‚    âœ“ retrieve_similar_patterns() [find analogous solutions]         â”‚
â”‚    âœ“ _group_pattern() [cluster similar patterns]                    â”‚
â”‚    âœ“ _compute_pattern_similarity() [pattern matching]               â”‚
â”‚    âœ“ Grid difference surprise detection (>30% = HIGH)                â”‚
â”‚                                                                             â”‚
â”‚  Key Methods:                                                               â”‚
â”‚    - compute_contextual_surprise() [multi-source surprise]           â”‚
â”‚    - solve_with_context() [use memory for solving]                   â”‚
â”‚    - retrieve_context() [attention-based retrieval]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ solver2.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Long-term permanent memory with problem classification             â”‚
â”‚  Key Components:                                                            â”‚
â”‚    âœ“ PermanentMemoryBank (DBSCAN clustering)                             â”‚
â”‚    âœ“ ProblemObjectiveExtractor (feature extraction)                      â”‚
â”‚    âœ“ PermanentSolver (uses permanent memory)                             â”‚
â”‚                                                                             â”‚
â”‚  Config (Lines 161-172):                                                  â”‚
â”‚    feature_dim = 256                                                  â”‚
â”‚    max_memories = 10000                                               â”‚
â”‚    DBSCAN eps = 0.3 (clustering threshold)                            â”‚
â”‚                                                                             â”‚
â”‚  Key Methods:                                                               â”‚
â”‚    - store_memory() [store problem-solution pairs]                    â”‚
â”‚    - retrieve_similar_problems() [find analogous problems]           â”‚
â”‚    - get_cluster_statistics() [monitor clustering health]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         DATA & FEATURE FILES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ dataset_arc.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Load and manage ARC dataset                                        â”‚
â”‚  Key Class:                                                                 â”‚
â”‚    ARCDataset(path, split="train")                                         â”‚
â”‚                                                                             â”‚
â”‚  Responsibilities:                                                          â”‚
â”‚    âœ“ Load training.json file                                             â”‚
â”‚    âœ“ Split into train/test/validation                                   â”‚
â”‚    âœ“ Provide problem grids and outputs                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ feature_extraction.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Extract transformation features from input-output pairs            â”‚
â”‚  Key Function:                                                              â”‚
â”‚    extract_transformation_features(input_grid, output_grid)                â”‚
â”‚                                                                             â”‚
â”‚  Output: 15-dimensional feature vector                                      â”‚
â”‚    1. size_change_ratio                                                   â”‚
â”‚    2. size_preserved                                                      â”‚
â”‚    3. pixel_change_ratio                                                  â”‚
â”‚    4. color_preservation                                                  â”‚
â”‚    5. spatial_correlation                                                 â”‚
â”‚    6-15. (symmetry, density, colors added/removed, etc.)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ feature_registry.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Manage feature extraction operators                               â”‚
â”‚  Key Class:                                                                 â”‚
â”‚    FeatureRegistry()                                                        â”‚
â”‚                                                                             â”‚
â”‚  Responsibilities:                                                          â”‚
â”‚    âœ“ Load operators from operators.yaml                                   â”‚
â”‚    âœ“ Apply operators to features                                          â”‚
â”‚    âœ“ Combine features for training                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ configs/operators.yaml â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Purpose: Configure feature extraction operators                            â”‚
â”‚  Type: External YAML configuration file                                     â”‚
â”‚  Contents: Feature operator definitions and parameters                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                       ALTERNATIVE LOSS FILES (Optional)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

grid_accuracy_loss.py        Focus on pixel-by-pixel grid accuracy
grid_transformation_loss.py  Focus on transformation properties (shape, color, etc.)
priority_efe_loss.py         Priority-based EFE with curriculum learning


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                          FILE DEPENDENCY GRAPH
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

run_main.py
    â”œâ”€â”€ train_sequence.py (TrainingConfig, TrainingLogger)
    â”‚   â”œâ”€â”€ dataset_arc.py (ARCDataset)
    â”‚   â”œâ”€â”€ qwen_hybrid_prompt.py (QwenHybridPrompt, QwenCfg)
    â”‚   â”œâ”€â”€ loss_function.py (ARCPromptGuidedAgent, EFELoss)
    â”‚   â”œâ”€â”€ revthink_orchestrator.py (RevThinkOrchestrator, RevThinkCfg)
    â”‚   â”œâ”€â”€ tta.py (TestTimeAdaptationSystem)
    â”‚   â”œâ”€â”€ feature_registry.py (FeatureRegistry)
    â”‚   â””â”€â”€ feature_extraction.py (extract_transformation_features)
    â”‚
    â””â”€â”€ test_sequence.py (TestConfig)
        â””â”€â”€ (uses same models as train_sequence.py)

run_gpu_finetuned.py â†’ trainloop_gpu_finetuned.py (main)
    â”œâ”€â”€ dataset_arc.py (ARCDataset)
    â”œâ”€â”€ qwen_hybrid_prompt.py (QwenHybridPrompt, QwenCfg)
    â”œâ”€â”€ loss_function.py (EFELoss, ARCPromptGuidedAgent)
    â”œâ”€â”€ revthink_orchestrator.py (RevThinkOrchestrator, RevThinkCfg)
    â”œâ”€â”€ tta.py (TestTimeAdaptationSystem)
    â”œâ”€â”€ solver2.py (PermanentSolver)
    â”œâ”€â”€ feature_registry.py (FeatureRegistry)
    â””â”€â”€ feature_extraction.py (extract_transformation_features)

run_cpu_simple.py â†’ trainloop.py (train_one_epoch)
    â””â”€â”€ (uses same models as above)


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SUMMARY: 21 FILES TOTAL
  â€¢ 3 Entry points (run_*.py)
  â€¢ 4 Core training (train_sequence.py, trainloop.py, trainloop_gpu_finetuned.py, test_sequence.py)
  â€¢ 6 Model architecture (loss_function.py, qwen_hybrid_prompt.py, revthink_orchestrator.py, tta.py, solver1.py, solver2.py)
  â€¢ 4 Data & features (dataset_arc.py, feature_extraction.py, feature_registry.py, operators.yaml)
  â€¢ 3 Alternative losses (optional)
  â€¢ 1 Utility/benchmarking

ğŸ’¾ Configuration stored in: 6 locations (hardcoded, functions, dataclasses, CLI, env vars, YAML)

ğŸ“Š Total configurable parameters: 50+

ğŸš€ READY TO TRAIN!
